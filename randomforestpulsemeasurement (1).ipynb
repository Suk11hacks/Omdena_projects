{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The extraction of Pulse rate from the video file for 1 video file - video id : Copy of SL133"
      ],
      "metadata": {
        "id": "hmr3PhCAi33r"
      },
      "id": "hmr3PhCAi33r"
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "g_gWThVdoSWh"
      },
      "id": "g_gWThVdoSWh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #importing required libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from scipy.signal import find_peaks, butter, filtfilt, welch\n",
        "\n",
        "# ‚úÖ Butterworth Bandpass Filter : Butterworth bandpass filter to remove noise and retain only the frequencies related to pulse rate. Here lowcut=0.7 Hz and highcut=3.0 Hz restrict the frequency range to typical human heart rate (42 - 180 BPM).butter(order, [low, high], btype='band') creates the filter.\n",
        "def butter_bandpass_filter(data, lowcut=0.7, highcut=3.0, fs=30, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return filtfilt(b, a, data)\n",
        "\n",
        "# ‚úÖ Extract Pulse from Video\n",
        "def extract_pulse(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"‚ö†Ô∏è Cannot open video file: {video_path}\")\n",
        "        return None\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)  # ‚úÖ Extract Frames per Second (FPS)\n",
        "    heart_rates = []\n",
        "\n",
        "    while True:                     #frame processing loop\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # ‚úÖ Extract Forehead Region (Forehead region being the Region of Interest (ROI))\n",
        "        roi = frame[50:150, 100:250]\n",
        "        mean_intensity = np.mean(roi)  # ‚úÖ Get mean pixel intensity which computes the average brightness of the ROI. heart_rates.append(mean_intensity): Stores the mean pixel intensity as a proxy for pulse signals.\n",
        "        heart_rates.append(mean_intensity)\n",
        "\n",
        "    cap.release()  # ‚úÖ Release Video Capture\n",
        "\n",
        "    # ‚úÖ Ensure we have enough frames for processing\n",
        "    if len(heart_rates) < 30:\n",
        "        print(\"‚ö†Ô∏è Not enough frames for pulse extraction!\")\n",
        "        return None\n",
        "\n",
        "    # ‚úÖ Apply Bandpass Filter :Filters the intensity values to remove noise and retain only relevant heart rate signals.\n",
        "    filtered_signal = butter_bandpass_filter(heart_rates, lowcut=0.7, highcut=3.0, fs=fps)\n",
        "\n",
        "#two methods used for filtering signal and then both combined using their weighted combination.\n",
        "\n",
        "    # ‚úÖ Method 1: Peak Detection (Higher Threshold for True Peaks)\n",
        "    peaks, _ = find_peaks(filtered_signal, distance=int(fps * 0.5), prominence=0.07 * np.std(filtered_signal))\n",
        "    peak_based_pulse = (len(peaks) / (len(heart_rates) / fps)) * 60\n",
        "\n",
        "    # ‚úÖ Method 2: Welch‚Äôs Power Spectral Density (Better FFT)\n",
        "    f_welch, Pxx_welch = welch(filtered_signal, fs=fps, nperseg=len(filtered_signal) // 2)\n",
        "    valid_freqs = (f_welch > 0.7) & (f_welch < 3.0)\n",
        "    if np.any(valid_freqs):\n",
        "        dominant_freq = f_welch[valid_freqs][np.argmax(Pxx_welch[valid_freqs])]\n",
        "        fft_based_pulse = dominant_freq * 60\n",
        "    else:\n",
        "        fft_based_pulse = 0  # Default if no valid frequency is found\n",
        "\n",
        "    # ‚úÖ Final Weighted Pulse Calculation (Increased FFT Weight)\n",
        "    final_pulse_rate = (peak_based_pulse * 0.35) + (fft_based_pulse * 0.80)\n",
        "\n",
        "    return {\n",
        "        \"video_id\": os.path.basename(video_path).replace(\".mp4\", \"\"),\n",
        "        \"peak_based_pulse\": round(peak_based_pulse, 2),\n",
        "        \"fft_based_pulse\": round(fft_based_pulse, 2),\n",
        "        \"final_pulse_rate\": round(final_pulse_rate, 2)\n",
        "    }\n",
        "\n",
        "# ‚úÖ Test Extraction on a Sample Video\n",
        "video_path = \"/content/sample_data/testvideo/Copy of SL133.mp4\"  # Update with actual path\n",
        "result = extract_pulse(video_path)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctDOnXeQTB5V",
        "outputId": "659d2e57-ac75-4e2d-9561-def14123e40f"
      },
      "id": "ctDOnXeQTB5V",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'video_id': 'Copy of SL133', 'peak_based_pulse': 72.59, 'fft_based_pulse': 79.47, 'final_pulse_rate': 88.98}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The extraction of Pulse rate from multiple video files"
      ],
      "metadata": {
        "id": "UcwK29WBi_pt"
      },
      "id": "UcwK29WBi_pt"
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#import cv2\n",
        "#import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "#from scipy.signal import find_peaks, butter, filtfilt, welch\n",
        "\n",
        "\n",
        "# ‚úÖ Define the folder containing videos (Update this path)\n",
        "video_folder = \"/content/sample_data\"\n",
        "\n",
        "\n",
        "# ‚úÖ Butterworth Bandpass Filter\n",
        "def butter_bandpass_filter(data, lowcut=0.7, highcut=3.0, fs=30, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return filtfilt(b, a, data)\n",
        "\n",
        "# ‚úÖ Extract Pulse from a Single Video\n",
        "def extract_pulse(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"‚ö†Ô∏è Cannot open video file: {video_path}\")\n",
        "        return None\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)  # ‚úÖ Extract Frames per Second (FPS)\n",
        "    heart_rates = []\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # ‚úÖ Extract Forehead Region (Adjust ROI if needed)\n",
        "        roi = frame[50:150, 100:250]  # Example ROI\n",
        "        mean_intensity = np.mean(roi)  # ‚úÖ Get mean pixel intensity\n",
        "        heart_rates.append(mean_intensity)\n",
        "\n",
        "    cap.release()  # ‚úÖ Release Video Capture\n",
        "\n",
        "    # ‚úÖ Ensure we have enough frames for processing\n",
        "    if len(heart_rates) < 30:\n",
        "        print(f\"‚ö†Ô∏è Not enough frames for {video_path}!\")\n",
        "        return None\n",
        "\n",
        "    # ‚úÖ Apply Bandpass Filter\n",
        "    filtered_signal = butter_bandpass_filter(heart_rates, lowcut=0.7, highcut=3.0, fs=fps)\n",
        "\n",
        "    # ‚úÖ Method 1: Peak Detection\n",
        "    peaks, _ = find_peaks(filtered_signal, distance=int(fps * 0.5), prominence=0.07 * np.std(filtered_signal))\n",
        "    peak_based_pulse = (len(peaks) / (len(heart_rates) / fps)) * 60\n",
        "\n",
        "    # ‚úÖ Method 2: Welch‚Äôs Power Spectral Density\n",
        "    f_welch, Pxx_welch = welch(filtered_signal, fs=fps, nperseg=len(filtered_signal) // 2)\n",
        "    valid_freqs = (f_welch > 0.7) & (f_welch < 3.0)\n",
        "    if np.any(valid_freqs):\n",
        "        dominant_freq = f_welch[valid_freqs][np.argmax(Pxx_welch[valid_freqs])]\n",
        "        fft_based_pulse = dominant_freq * 60\n",
        "    else:\n",
        "        fft_based_pulse = 0  # Default if no valid frequency is found\n",
        "\n",
        "    # ‚úÖ Final Weighted Pulse Calculation\n",
        "    final_pulse_rate = (peak_based_pulse * 0.35) + (fft_based_pulse * 0.80)\n",
        "\n",
        "    return {\n",
        "        \"video_id\": os.path.basename(video_path),\n",
        "        \"peak_based_pulse\": round(peak_based_pulse, 2),\n",
        "        \"fft_based_pulse\": round(fft_based_pulse, 2),\n",
        "        \"final_pulse_rate\": round(final_pulse_rate, 2)\n",
        "    }\n",
        "\n",
        "# ‚úÖ Process All Videos in Google Drive Folder : the loop for running the above code (same as for 1 video file )\n",
        "results = []\n",
        "for file_name in os.listdir(video_folder):\n",
        "    if file_name.endswith(\".mp4\"):\n",
        "        video_path = os.path.join(video_folder, file_name)\n",
        "        print(f\"üöÄ Processing: {file_name}\")\n",
        "        result = extract_pulse(video_path)\n",
        "        if result:\n",
        "            results.append(result)\n",
        "\n",
        "# ‚úÖ Save Results to CSV\n",
        "output_csv = \"/content/drive/My Drive/pulse_results.csv\"\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(output_csv, index=False)\n",
        "print(f\"‚úÖ Results saved to {output_csv}\")\n",
        "\n",
        "# ‚úÖ Print Summary\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMIKu_mLTCto",
        "outputId": "d4c73fc8-ed17-49b5-e24e-d7181b1371c9"
      },
      "id": "nMIKu_mLTCto",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üöÄ Processing: Copy of SL496.mp4\n",
            "üöÄ Processing: Copy of IN901.mp4\n",
            "üöÄ Processing: Copy of SL191.mp4\n",
            "üöÄ Processing: Copy of SL225.mp4\n",
            "üöÄ Processing: Copy of SL413.mp4\n",
            "‚úÖ Results saved to /content/drive/My Drive/pulse_results.csv\n",
            "            video_id  peak_based_pulse  fft_based_pulse  final_pulse_rate\n",
            "0  Copy of SL496.mp4             66.84            51.93             64.93\n",
            "1  Copy of IN901.mp4             63.04            47.16             59.79\n",
            "2  Copy of SL191.mp4             69.99            49.30             63.94\n",
            "3  Copy of SL225.mp4             69.61            60.24             72.56\n",
            "4  Copy of SL413.mp4             65.50            51.61             64.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results above are inconsistent for multiple videos but accurate for single sample as depicted above"
      ],
      "metadata": {
        "id": "vcKCwwJ8oxr-"
      },
      "id": "vcKCwwJ8oxr-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the results obtained from the above measurement for training the model for prediction of pulse rate"
      ],
      "metadata": {
        "id": "FgVk67iLpCxh"
      },
      "id": "FgVk67iLpCxh"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def extract_features_from_video(video_path):\n",
        "    \"\"\"Extract features from a given video.\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    heart_rates = []\n",
        "    frame_skip = 10\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"‚ö†Ô∏è Cannot open video file: {video_path}\")\n",
        "        return None\n",
        "\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_count % frame_skip == 0:\n",
        "            frame = cv2.resize(frame, (640, 480))\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            h, w = gray.shape\n",
        "            forehead = gray[int(0.2*h):int(0.3*h), int(0.3*w):int(0.7*w)]\n",
        "            heart_rates.append(np.mean(forehead))\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if len(heart_rates) == 0:\n",
        "        print(\"‚ö†Ô∏è No valid frames extracted for heart rate calculation!\")\n",
        "        return None\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return {\n",
        "        \"video_id\": os.path.basename(video_path).replace(\".mp4\", \"\"),\n",
        "        \"processing_time_sec\": round(elapsed_time, 2)\n",
        "    }\n",
        "\n",
        "def predict_pulse_rate(video_path, model_path):\n",
        "    \"\"\"Predict pulse rate from a new video using a trained model.\"\"\"\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"‚ùå Model file not found at: {model_path}\")\n",
        "        return None\n",
        "\n",
        "    model = joblib.load(model_path)\n",
        "    features = extract_features_from_video(video_path)\n",
        "\n",
        "    if features is None:\n",
        "        print(\"‚ùå Could not extract features from video.\")\n",
        "        return None\n",
        "\n",
        "    feature_df = pd.DataFrame([features])[['processing_time_sec']]\n",
        "    predicted_pulse = model.predict(feature_df)[0]\n",
        "\n",
        "    print(f\"üéØ Predicted Pulse Rate: {predicted_pulse:.2f} BPM\")\n",
        "    return predicted_pulse\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# **üìå Example: Predict Pulse Rate from a New Video**\n",
        "# -------------------------------------------------------------------------------\n",
        "new_video = \"/content/sample_data/testvideo/Copy of SL133.mp4\"  # Change path to your test video\n",
        "model_path = \"/content/sample_data/trained_model.pkl\"  # Specify the model path\n",
        "\n",
        "predicted_pulse = predict_pulse_rate(new_video, model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co_F68e7vC5G",
        "outputId": "fe7119c4-1aa5-48f4-8415-b77d7566ba3b"
      },
      "id": "co_F68e7vC5G",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Predicted Pulse Rate: 73.20 BPM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "joqgNA2KxTJ-"
      },
      "id": "joqgNA2KxTJ-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}